---
title: "Task 3 - Text Wrangling and Analysis"
author: "Max Settineri"
date: "2023-03-21"
output: 
  html_document:
    code_folding: hide
    theme: darkly
---

# Overview

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(tidytext)
library(textdata)
library(pdftools)
library(ggwordcloud)
library(here)
library(stringr)
```

```{r}
shouse_five <- pdf_text(here("data/shouse_five.pdf"))
```

## Text wrangling

```{r}
##Get text into a dataframe and tokenize
shouse_lines <- data.frame(shouse_five) %>% 
  mutate(page = 1:n()) %>%
  mutate(text_full = str_split(shouse_five, pattern = '\n')) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full))

## adding chapter info to the data frame
shouse_chapts <- shouse_lines %>% 
  slice(-(1:75)) %>% ## removing pages before chapter 1
  mutate(chapter = ifelse(str_detect(text_full, "^\\w+$") & !str_trim(text_full) %in% c("COURAGE"), text_full, NA)) %>% 
  fill(chapter, .direction = 'down') 

## getting tokens into words
shouse_words <- shouse_chapts %>% 
  unnest_tokens(word, text_full, token = 'words')

## removing stop words
shouse_words_clean <- shouse_words %>% 
  anti_join(stop_words, by = 'word')

non_stop_counts <- shouse_words_clean %>% 
  count(chapter, word)
```

## Find the top 100 words from the book

```{r}
top_100_words <- non_stop_counts %>% 
  slice_max(order_by = n, n = 100)

ggplot(data = top_5_words, aes(x = n, y = word)) +
  geom_col(fill = "blue") +
  facet_wrap(~ chapter, scales = "free")
```

## Make a word cloud for chapter 1

```{r}
ch1_top100 <- non_stop_counts %>% 
  filter(chapter == 1) %>% 
  slice_max(order_by = n, n = 100)

ch1_cloud <- ggplot(data = ch1_top100, aes(label = word)) +
  geom_text_wordcloud(aes(color = n, size = n), shape = 'diamond') +
  scale_size_area(max_size = 6) +
  scale_color_gradientn(colors = c('darkgreen', 'blue', 'purple'))

ch1_cloud
```

